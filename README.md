# Pipeline de PrÃ©-processamento de Dados JurÃ­dicos

[![C++17](https://img.shields.io/badge/C%2B%2B-17-blue.svg)](https://en.cppreference.com/w/cpp/17)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![codecov](https://codecov.io/gh/username/graph_priority_summary/branch/main/graph/badge.svg)](https://codecov.io/gh/username/graph_priority_summary)

Este projeto implementa um **pipeline modular de prÃ©-processamento de dados jurÃ­dicos** em C++ utilizando um grafo de dependÃªncias para orquestraÃ§Ã£o paralela de tarefas. O sistema processa documentos jurÃ­dicos atravÃ©s de mÃºltiplas etapas de transformaÃ§Ã£o, incluindo limpeza de texto, tokenizaÃ§Ã£o BPE, partiÃ§Ã£o, adiÃ§Ã£o de tokens especiais, conversÃ£o para Ã­ndices e simulaÃ§Ã£o de embeddings.

## ğŸ—ï¸ Arquitetura do Sistema

O projeto foi **completamente modularizado** seguindo as melhores prÃ¡ticas de engenharia de software. O pipeline Ã© estruturado como um grafo de dependÃªncias onde cada nÃ³ representa uma tarefa de processamento. O scheduler gerencia a execuÃ§Ã£o paralela respeitando as dependÃªncias entre tarefas e suas prioridades.

### âš¡ Principais CaracterÃ­sticas

- âœ… **DetecÃ§Ã£o automÃ¡tica de CPUs**: Utiliza automaticamente todas as threads disponÃ­veis
- âœ… **ExecuÃ§Ã£o paralela e sequencial**: ComparaÃ§Ã£o automÃ¡tica de performance
- âœ… **CompilaÃ§Ã£o limpa**: Zero warnings com flags rigorosas de compilaÃ§Ã£o
- âœ… **Arquitetura modular**: CÃ³digo organizado em namespaces e mÃ³dulos bem definidos
- âœ… **Sistema de build robusto**: Suporte a Makefile e CMake

### â›“ï¸ Fluxo do Pipeline

```
Dados CSV â†’ CleanText â†’ NormalizeText â†’ WordTokenization â†’ BPETokenization
                                                                â†“
GenerateEmbeddings â† TokensToIndices â† AddSpecialTokens â† PartitionTokens
```

## ğŸ” Etapas do Pipeline Detalhadas

| Etapa | FunÃ§Ã£o | DescriÃ§Ã£o | Entrada | SaÃ­da |
|-------|--------|-----------|---------|--------|
| 1 | `cleanText` | Remove HTML, caracteres especiais | Texto bruto | Texto limpo |
| 2 | `normalizeText` | Converte para minÃºsculas | Texto limpo | Texto normalizado |
| 3 | `wordTokenization` | Separa palavras e pontuaÃ§Ã£o | Texto normalizado | Tokens de palavras |
| 4 | `bpeTokenization` | Aplica Byte Pair Encoding | Tokens de palavras | Sub-tokens BPE |
| 5 | `partitionTokens` | Limita sequÃªncias por tamanho | Sub-tokens BPE | SequÃªncias limitadas |
| 6 | `addSpecialTokens` | Adiciona [CLS], [SEP], [EOF] | SequÃªncias limitadas | SequÃªncias com tokens especiais |
| 7 | `tokensToIndices` | Converte tokens para IDs | Tokens textuais | IDs numÃ©ricos |
| 8 | `generateEmbeddings` | Simula geraÃ§Ã£o de embeddings | IDs numÃ©ricos | Embeddings simulados |

### ğŸ” Arquitetura Modular

O sistema estÃ¡ organizado em namespaces e mÃ³dulos bem definidos:

- **`legal_doc_pipeline`**: Namespace principal do projeto
- **`legal_doc_pipeline::utils`**: UtilitÃ¡rios (CSV reader, timer)
- **`legal_doc_pipeline::pipeline`**: Componentes do pipeline (manager, text processor)
- **`legal_doc_pipeline::scheduler`**: Sistema de agendamento de tarefas

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ include/                          # Arquivos de cabeÃ§alho
â”‚   â”œâ”€â”€ types.h                       # Tipos e estruturas fundamentais
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ pipeline_manager.h        # Gerenciador principal do pipeline
â”‚   â”‚   â””â”€â”€ text_processor.h          # Processador de texto modular
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”‚   â””â”€â”€ workflow_scheduler.h      # Scheduler de workflow
â”‚   â”œâ”€â”€ tokenizer/
â”‚   â”‚   â””â”€â”€ tokenizer_wrapper.h       # Wrapper do tokenizador BPE
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ csv_reader.h              # Leitor de arquivos CSV
â”‚       â””â”€â”€ timer.h                   # UtilitÃ¡rio de mediÃ§Ã£o de tempo
â”œâ”€â”€ src/                              # ImplementaÃ§Ãµes
â”‚   â”œâ”€â”€ types.cpp                     # ImplementaÃ§Ã£o dos tipos bÃ¡sicos
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ pipeline_manager.cpp      # ImplementaÃ§Ã£o do gerenciador
â”‚   â”‚   â””â”€â”€ text_processor.cpp        # ImplementaÃ§Ã£o do processador
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”‚   â””â”€â”€ workflow_scheduler.cpp    # ImplementaÃ§Ã£o do scheduler
â”‚   â”œâ”€â”€ tokenizer/
â”‚   â”‚   â””â”€â”€ tokenizer_wrapper.cpp     # ImplementaÃ§Ã£o do tokenizador
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ csv_reader.cpp            # ImplementaÃ§Ã£o do leitor CSV
â”‚       â””â”€â”€ timer.cpp                 # ImplementaÃ§Ã£o do timer
â”œâ”€â”€ main_modular.cpp                  # AplicaÃ§Ã£o principal modular
â”œâ”€â”€ main.cpp                          # VersÃ£o legacy (mantida para comparaÃ§Ã£o)
â”œâ”€â”€ Makefile                          # Sistema de build com Make
â”œâ”€â”€ CMakeLists.txt                    # Sistema de build com CMake
â”œâ”€â”€ LICENSE                           # LicenÃ§a do projeto
â”œâ”€â”€ dataset.csv                       # Dataset de entrada
â””â”€â”€ README.md                         # Esta documentaÃ§Ã£o
```

## :hammer_and_pick: Funcionalidades

### DetecÃ§Ã£o AutomÃ¡tica de Hardware
```cpp
// Detecta automaticamente o nÃºmero de threads disponÃ­veis
unsigned int max_threads = std::thread::hardware_concurrency();
config.num_workers = max_threads;
```

### ValidaÃ§Ã£o de Grafo
- **DetecÃ§Ã£o de ciclos**: Algoritmo DFS para validar dependÃªncias
- **RepresentaÃ§Ã£o visual**: GeraÃ§Ã£o de string do grafo para debug
- **VerificaÃ§Ã£o de consistÃªncia**: ValidaÃ§Ã£o automÃ¡tica antes da execuÃ§Ã£o


## ğŸ§ª Testes e ValidaÃ§Ã£o

- âœ… **ValidaÃ§Ã£o de entrada**: VerificaÃ§Ã£o de arquivos CSV e colunas
- âœ… **DetecÃ§Ã£o de ciclos**: ValidaÃ§Ã£o do grafo de dependÃªncias
- âœ… **Gerenciamento de recursos**: Threads, mutexes, memÃ³ria
- âœ… **Tratamento de erros**: ExceÃ§Ãµes e casos extremos
- âœ… **CompilaÃ§Ã£o limpa**: Zero warnings com flags rigorosas



## ğŸš€ CompilaÃ§Ã£o e ExecuÃ§Ã£o com Makefile

```bash
# Compilar 
make

# Compilar com debug
make debug

# Executar
make run

# Limpar arquivos de build
make clean

# Mostrar ajuda
make help
```

### ğŸ“Š Resultados Obtidos
```
â±ï¸  TEMPOS DE EXECUÃ‡ÃƒO:
  Pipeline Paralelo (Scheduler):     5.0324 segundos
  Pipeline Sequencial (Thread Ãšnica): 4.8970 segundos
  Pipeline Paralelo (Particionado):   0.9342 segundos

ğŸš€ SPEEDUPS:
  Scheduler vs Sequencial:     0.9731x (PIOR)
  Particionado vs Sequencial:  5.2420x (MELHOR)
  Particionado vs Scheduler:   5.3871x (MELHOR)

ğŸ“ˆ THROUGHPUT (documentos/segundo):
  Scheduler:     9532.5566
  Sequencial:    9796.2818
  Particionado:  51352.4276

ğŸ† PARTICIONAMENTO DE DADOS PARALELIZADO Ã© a melhor estratÃ©gia para este fluxo de dados. âœ…
```

## ğŸ¯ **RESUMO FINAL**

O pipeline baseado em Grafo de Prioridades para prÃ©-processamento de textos jurÃ­dicos foi **aprimorado com sucesso** para explorar paralelismo real atravÃ©s de **particionamento de dados**.

### **ğŸš€ PRINCIPAIS IMPLEMENTAÃ‡Ã•ES**

#### **1. Modo Paralelo com Particionamento de Dados**
- **MÃ©todo `runParallelPartitioned()`**: Divide os dados em chunks e processa cada chunk em paralelo
- **Particionamento inteligente**: Calcula automaticamente o tamanho ideal dos chunks baseado no nÃºmero de workers
- **Processamento real em paralelo**: Cada worker processa um chunk completo independentemente
- **Speedup significativo**: AtÃ© **5.24x** mais rÃ¡pido que o modo sequencial

#### **2. TrÃªs CenÃ¡rios de ExecuÃ§Ã£o**
- **Sequencial**: ExecuÃ§Ã£o em thread Ãºnica para baseline
- **Paralelo Tradicional**: Scheduler com grafo de dependÃªncias (limitado pela natureza linear do pipeline)
- **Paralelo Particionado**: DivisÃ£o dos dados para paralelismo real

#### **3. ComparaÃ§Ã£o AutomÃ¡tica de Performance**
- **MÃ©todo `runFullComparison()`**: Executa os trÃªs cenÃ¡rios automaticamente
- **AnÃ¡lise detalhada**: Speedup, eficiÃªncia, throughput para cada modo
- **ValidaÃ§Ã£o de consistÃªncia**: Verifica se todos os modos produzem resultados idÃªnticos
- **RecomendaÃ§Ã£o automÃ¡tica**: Indica o melhor modo para o volume de dados


### **ğŸ† CONCLUSÃƒO**

O projeto foi bem-sucedido em todos os aspectos:

1. **âœ… Paralelismo real implementado** atravÃ©s de particionamento de dados
2. **âœ… TrÃªs modos de execuÃ§Ã£o** validados e comparados
3. **âœ… Performance significativamente melhorada** (5.24x speedup)
4. **âœ… EstatÃ­sticas detalhadas** implementadas para todos os cenÃ¡rios
5. **âœ… CÃ³digo limpo e documentado** sem warnings de compilaÃ§Ã£o
6. **âœ… ValidaÃ§Ã£o completa** com testes de consistÃªncia e performance


## ğŸ“ˆ Roadmap e PrÃ³ximos Passos

- [ ] **IntegraÃ§Ã£o com HuggingFace Tokenizers (pybind)**
- [ ] **Suporte a modelos de embedding reais (LibTorch/ONNX)**
- [ ] **Interface de linha de comando mais robusta**
- [ ] **Suporte a mÃºltiplos formatos de entrada (JSON, Parquet)**

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ‘¥ Autores e Contribuidores

- **[Gustavo Alexandre Santos](https://github.com/gassantos)** - *Desenvolvimento principal e arquitetura*

## ğŸ“š ReferÃªncias e Recursos

- [Modern C++ Core Guidelines](https://isocpp.github.io/CppCoreGuidelines/)
- [Google C++ Style Guide](https://google.github.io/styleguide/cppguide.html)
- [HuggingFace Tokenizers](https://huggingface.co/docs/tokenizers/)
- [Byte Pair Encoding (BPE)](https://arxiv.org/abs/1508.07909)
- [BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805)

---
