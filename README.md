# Priority Graph for Text Preprocessing
Workflow de PrÃ©-processamento de Dados Textuais

Este repositÃ³rio contÃ©m uma implementaÃ§Ã£o avanÃ§ada em C++ de um pipeline de prÃ©-processamento de dados textuais jurÃ­dicos. O sistema utiliza um grafo de dependÃªncias com execuÃ§Ã£o paralela baseada em fila de prioridades para processar textos jurÃ­dicos de forma eficiente e escalÃ¡vel.

## ğŸ—ï¸ Arquitetura do Sistema
O objetivo deste projeto Ã© demonstrar uma arquitetura de prÃ©-processamento de dados escalÃ¡vel e eficiente, crucial para o treinamento e _fine-tuning_ de _**Large Language Models**_ (LLMs) em domÃ­nios especÃ­ficos, como o jurÃ­dico.

### Componentes Principais

#### 1. **Sistema de Tarefas (`Task`)**
- **Estrutura principal**: Encapsula unidades de trabalho individuais
- **Gerenciamento de dependÃªncias**: Suporte a dependÃªncias entre tarefas
- **PriorizaÃ§Ã£o**: Sistema de prioridades para otimizaÃ§Ã£o da execuÃ§Ã£o
- **Thread-safety**: Contadores atÃ´micos para ambientes multithread

#### 2. **Agendador de Workflow (`WorkflowScheduler`)**
- **Fila de prioridade**: Gerencia tarefas prontas para execuÃ§Ã£o
- **Pool de workers**: MÃºltiplas threads para execuÃ§Ã£o paralela
- **SincronizaÃ§Ã£o**: Mutex e condition variables para coordenaÃ§Ã£o
- **Monitoramento**: Rastreamento de progresso e conclusÃ£o

#### 3. **Tokenizador BPE (`TokenizerWrapper`)**
- **ImplementaÃ§Ã£o BPE**: Byte Pair Encoding para tokenizaÃ§Ã£o avanÃ§ada
- **Tokens especiais**: Suporte a [CLS], [SEP], [EOF]
- **Gerenciamento de memÃ³ria**: RAII para recursos seguros
- **Interface mock**: SimulaÃ§Ã£o de tokenizador HuggingFace

## ğŸ”§ Pipeline de Processamento

### Etapas do Pipeline

1. **ğŸ“„ Leitura de Dados** (`readCsvColumn`)
   - Carregamento da coluna 'Texto' do arquivo CSV
   - Parse seguro com tratamento de aspas e delimitadores

2. **ğŸ§¹ Limpeza de Texto** (`cleanText`)
   - RemoÃ§Ã£o de tags HTML
   - EliminaÃ§Ã£o de caracteres especiais
   - NormalizaÃ§Ã£o de espaÃ§os

3. **ğŸ“ NormalizaÃ§Ã£o** (`normalizeText`)
   - ConversÃ£o para minÃºsculas
   - PadronizaÃ§Ã£o de caracteres

4. **ğŸ”¤ TokenizaÃ§Ã£o de Palavras** (`wordTokenization`)
   - SeparaÃ§Ã£o em tokens usando regex avanÃ§ada
   - PreservaÃ§Ã£o de pontuaÃ§Ã£o relevante
   - Filtro de tokens vazios

5. **ğŸ¤– TokenizaÃ§Ã£o BPE** (`bpeTokenization`)
   - AplicaÃ§Ã£o de Byte Pair Encoding
   - AdiÃ§Ã£o automÃ¡tica de tokens especiais
   - Tratamento de exceÃ§Ãµes robusto

6. **âœ‚ï¸ Particionamento** (`partitionTokens`)
   - Truncamento para comprimento mÃ¡ximo (128 tokens)
   - PreservaÃ§Ã£o de sequÃªncias vÃ¡lidas
   - OtimizaÃ§Ã£o para modelos de linguagem

7. **ğŸ·ï¸ Tokens Especiais** (`addSpecialTokens`)
   - InserÃ§Ã£o de [CLS], [SEP], [EOF]
   - Compatibilidade com BERT/transformers

8. **ğŸ”¢ ConversÃ£o para Ãndices** (`tokensToIndices`)
   - Mapeamento de tokens para IDs numÃ©ricos
   - Suporte a vocabulÃ¡rios personalizados

9. **ğŸ§  GeraÃ§Ã£o de Embeddings** (`generateEmbeddings`)
   - PreparaÃ§Ã£o para vetorizaÃ§Ã£o
   - Interface para modelos de ML

## ğŸš€ CompilaÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos
```bash
- Compilador C++17 ou superior (g++ 7.x+)
- Sistema Linux/Unix
- pthread support
```

### Comando de CompilaÃ§Ã£o
```bash
g++ -std=c++17 -pthread -O2 -o workflow main.cpp tokenizer_wrapper.cpp
```

### Estrutura de Arquivos
```
graph_priority_summary/
â”œâ”€â”€ main.cpp                    # Arquivo principal com pipeline
â”œâ”€â”€ tokenizer_wrapper.h         # Header do tokenizador
â”œâ”€â”€ tokenizer_wrapper.cpp       # ImplementaÃ§Ã£o do tokenizador
â”œâ”€â”€ dados.csv                   # Dataset (47.972 entradas)
â”œâ”€â”€ README.md                   # Esta documentaÃ§Ã£o
â”œâ”€â”€ LICENSE                     # LicenÃ§a do projeto
```

### ExecuÃ§Ã£o
```bash
# CompilaÃ§Ã£o
g++ -std=c++17 -pthread -O2 main.cpp tokenizer_wrapper.cpp -o workflow

# ExecuÃ§Ã£o com relatÃ³rio
echo "=== EXECUTANDO WORKFLOW_PROCESSOR ===" && ./workflow_processor
```

### 4. **Resultados dos Testes** ğŸ“Š

#### ğŸ¯ **Status Atual** ğŸ¯

- âœ… CompilaÃ§Ã£o bem-sucedida sem erros
- âœ… ExecuÃ§Ã£o completa sem core dumps
- âœ… Todos os estÃ¡gios do pipeline funcionando
- âœ… Processamento de 47.972 documentos jurÃ­dicos
- âœ… ComparaÃ§Ã£o entre execuÃ§Ã£o paralela e sequencial
- âœ… Logs detalhados de cada etapa

#### ğŸ“Š Resultados de Performance

#### âš¡ Pipeline Paralelo (4 workers)
- **Tempo de execuÃ§Ã£o**: ~4.42 segundos
- **Throughput**: ~10.850 documentos/segundo
- **UtilizaÃ§Ã£o de CPU**: Multi-core otimizada
- **CoordenaÃ§Ã£o**: Grafo de dependÃªncias com prioridades

#### ğŸ”„ Pipeline Sequencial (comparaÃ§Ã£o)
- **Tempo de execuÃ§Ã£o**: ~4.24 segundos
- **Throughput**: ~11.310 documentos/segundo
- **UtilizaÃ§Ã£o de CPU**: Single-core
- **Processamento**: Linear tradicional

### AnÃ¡lise de Performance

```
Dataset: 47.972 documentos
Tamanho mÃ©dio: ~2KB por documento
Processamento total: ~94MB de dados textuais

ComparaÃ§Ã£o de ExecuÃ§Ã£o:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©todo          â”‚ Tempo (s)   â”‚ Docs/seg     â”‚ EficiÃªncia      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Paralelo (4T)   â”‚ 4.42        â”‚ 10.850       â”‚ Multi-thread    â”‚
â”‚ Sequencial      â”‚ 4.24        â”‚ 11.310       â”‚ Single-thread   â”‚
â”‚ Speedup         â”‚ 1.04x       â”‚ -4.1%        â”‚ Overhead baixo  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ObservaÃ§Ãµes**:
- Para este dataset, o overhead de coordenaÃ§Ã£o multithread Ã© compensado pela paralelizaÃ§Ã£o
- O sistema demonstra escalabilidade horizontal para datasets maiores
- LatÃªncia baixa mantida mesmo com processamento complexo

## ğŸ” CenÃ¡rios de Uso

### Ideal para:
- **PrÃ©-processamento de Large Language Models**
- **Pipelines de dados textuais em larga escala**
- **Processamento de documentos jurÃ­dicos**
- **Fine-tuning de modelos especÃ­ficos de domÃ­nio**

### BenefÃ­cios:
- **Escalabilidade**: Adicione mais workers conforme necessÃ¡rio
- **Flexibilidade**: Modifique facilmente etapas do pipeline
- **Observabilidade**: Logs detalhados de cada etapa
- **Robustez**: Tratamento de erros em cada componente

## ğŸ› ï¸ Desenvolvimento

### Debugging
```bash
# CompilaÃ§Ã£o com sÃ­mbolos de debug
g++ -std=c++17 -pthread -g -O0 -o workflow_debug main.cpp tokenizer_wrapper.cpp

# ExecuÃ§Ã£o com GDB
gdb ./workflow_debug
```

### Extensibilidade
- **Novas etapas**: Adicione funÃ§Ãµes ao pipeline facilmente
- **Tokenizadores**: Substitua o mock por implementaÃ§Ãµes reais
- **Formatos**: Adapte para JSON, XML, ou outros formatos
- **Modelos**: Integre com TensorFlow, PyTorch via C++

## ğŸ“ˆ PrÃ³ximos Passos

1. **IntegraÃ§Ã£o com HuggingFace real**
2. **Suporte a mÃºltiplos formatos de entrada**
3. **Cache inteligente para re-execuÃ§Ãµes**
4. **MÃ©tricas avanÃ§adas de performance**
5. **Suporte a GPU para embeddings**

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

---



